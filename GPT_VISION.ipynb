{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDvjRod_TMaX",
        "outputId": "37e2891d-b579-4397-a855-904e867e55d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.47.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.47.0-py3-none-any.whl (375 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.47.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kadfX2aEtIJ"
      },
      "outputs": [],
      "source": [
        "#make sure to always pip install openai when you open this, idk why but it gets mad at u otherwise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "T9tWSfPjwS_J",
        "outputId": "681491f9-a1d6-4ca0-aba2-442a1701a832"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b95cb820255e>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import cv2\n",
        "import base64\n",
        "import csv\n",
        "import re\n",
        "import os\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "def videoCapture(vid):\n",
        "    try:\n",
        "        video = cv2.VideoCapture(vid)\n",
        "        base64Frames = []\n",
        "        frame_count = 0\n",
        "\n",
        "        while video.isOpened():\n",
        "            success, frame = video.read()\n",
        "            if not success:\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "            if frame_count % 10 == 0:\n",
        "                _, buffer = cv2.imencode(\".jpg\", frame)\n",
        "                base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
        "\n",
        "\n",
        "        video.release()\n",
        "\n",
        "        response = openai.chat.completions.create(\n",
        "              model = \"gpt-4-vision-preview\",\n",
        "               messages=[\n",
        "                  {\"role\": \"system\", \"content\": \"You are an expert in identifying the sentiment of visual content. Currently working with the FBI, your task is to evaluate each frame of a video to determine if the video is 'toxic' or 'not toxic'. Think about this step by step. Please make sure to end every response stating, 'the prior reasoning is why the video is ________' with the underscores being either 'toxic' or 'not toxic'\"},\n",
        "                  {\"role\": \"user\", \"content\": [{'image' : frame} for frame in base64Frames[0:5]]}\n",
        "              ]\n",
        "          )\n",
        "\n",
        "        result = response\n",
        "\n",
        "        save_result_incrementally(response.choices[0].message.content)\n",
        "        print(f'Response: {response.choices[0].message.content}')\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'Error occurred with video: {vid}, error was: {e}')\n",
        "\n",
        "\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32cOLhmp3wjM"
      },
      "outputs": [],
      "source": [
        "# write more code for saving results into csv files\n",
        "\n",
        "\n",
        "# def save_result_incrementally(fullResponse, response):\n",
        "#     file_path = '/content/drive/My Drive/instagram-reels-dataset/results/'\n",
        "\n",
        "#     ogPath  = os.getcwd()\n",
        "\n",
        "#     os.chdir(file_path)\n",
        "\n",
        "#     with open('gpt-4-vision-preview-COT-full.csv', 'a', newline='', encoding='utf-8') as file: #full responsne\n",
        "#         writer = csv.writer(file)\n",
        "#         writer.writerow([fullResponse])\n",
        "\n",
        "#     with open('gpt-4-vision-preview-COT.csv', 'a', newline='', encoding='utf-8') as file: #only toxic or not\n",
        "#         writer = csv.writer(file)\n",
        "#         writer.writerow([response])\n",
        "\n",
        "#     os.chdir(ogPath)\n",
        "\n",
        "def save_result_incrementally(response):\n",
        "    file_path = '/content/drive/My Drive/instagram-reels-dataset/results/'\n",
        "\n",
        "    ogPath  = os.getcwd()\n",
        "\n",
        "    os.chdir(file_path)\n",
        "\n",
        "\n",
        "\n",
        "    with open('gpt-4-vision-preview-COT.csv', 'a', newline='', encoding='utf-8') as file: #only toxic or not\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([response])\n",
        "\n",
        "    os.chdir(ogPath)\n",
        "\n",
        "\n",
        "def csv_to_json(csv_file_path, json_file_path):\n",
        "    results = []\n",
        "\n",
        "    with open(csv_file_path, mode='r') as file:\n",
        "        csv_reader = csv.reader(file)\n",
        "\n",
        "        for row in csv_reader:\n",
        "            result = {\n",
        "                \"responses\": row[0],\n",
        "                \"truth\": row[1]\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "    with open(json_file_path, 'w') as json_file:\n",
        "        json.dump(results, json_file, indent=4)\n",
        "\n",
        "def load_results_from_json(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        results = json.load(f)\n",
        "    return results\n",
        "\n",
        "base_dir = '/content/drive/My Drive/instagram-reels-dataset'\n",
        "model_name = \"gpt-4-vision-preview\"\n",
        "dataset_name = \"toxicity\"\n",
        "\n",
        "# csv_base_filename = f'sc_clustering_{model_name}_{dataset_name}_RUN5'  # Be organized in how you name it\n",
        "# csv_file_path = os.path.join(base_dir, csv_base_filename + '.csv')\n",
        "\n",
        "# json_base_filename = f'sc_clustering_{model_name}_{dataset_name}'\n",
        "# json_file_path = os.path.join(base_dir, json_base_filename + '.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v98JW75H36Af"
      },
      "outputs": [],
      "source": [
        "# write code to extract the intended answer from the generation - you might need to few shot prompt GPT to get it to answer in a certain format\n",
        "\n",
        "# write some code to calculate accuracy\n",
        "\n",
        "\n",
        "\n",
        "# Store as much as you can. Better to save too much than too little. Memory constraints typically aren't a concern for saving results.\n",
        "\n",
        "# change the keys to be for what we are storing\n",
        "        # result = {\n",
        "        #     \"question\": question,\n",
        "        #     \"true_answer\": true_answer,\n",
        "        #     \"raw_output_answer\": raw_output_answer, # Note that it's recommended to also store the raw output answer, in case that you need to change your extraction function later.\n",
        "        #     \"extracted_output_answer\": extracted_output_answer,\n",
        "        #     \"numerical_true_answer\": numerical_true_answer,\n",
        "        #     \"numerical_output_answer\": numerical_output_answer\n",
        "        # }\n",
        "        # results.append(result)\n",
        "\n",
        "        # save_result_incrementally(result, csv_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6UGVXpUWg1n",
        "outputId": "480bfe14-afc7-45f8-d155-dd789cd9cd46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "def process_videos(subfolder):\n",
        "    # Main code function which will iterate through the reels or comments and return its extracted results\n",
        "\n",
        "      responses = []\n",
        "      ogPath = \"/content/drive/My Drive/instagram-reels-dataset/reels/\"\n",
        "\n",
        "\n",
        "      os.chdir(ogPath + subfolder)\n",
        "\n",
        "      if not os.path.exists(ogPath + subfolder) or not os.path.isdir(ogPath + subfolder):\n",
        "            print(f\"Subfolder {subfolder} does not exist or is not a directory. Skipping...\")\n",
        "\n",
        "      else:\n",
        "        files = sorted(os.listdir())\n",
        "\n",
        "        for file in files:\n",
        "\n",
        "            result = videoCapture(file)\n",
        "\n",
        "\n",
        "            responses.append(result)\n",
        "\n",
        "        os.chdir(ogPath)\n",
        "\n",
        "        return responses\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir(\"/content/drive/My Drive/instagram-reels-dataset/reels\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "WYnDcKH7bxfw",
        "outputId": "90c7a9e2-f2d3-408a-d24a-3743d3e5c4e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: The images show a sequence of frames from a video featuring a male news reporter. He is talking about something related to \"Authorities in Papua New Guinea,\" as indicated by the captions. While his facial expressions change slightly across the frames, nothing in the content of these images suggests anything toxic. The reporter is professionally dressed, the background appears to be a news studio, and he is not displaying any inappropriate behavior. Therefore, based on the provided images, the video seems to be a regular news report and does not exhibit any characteristics that would classify it as toxic.\n",
            "\n",
            "The prior reasoning is why the video is not toxic.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-0113df129c0d>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-0e9d036daf4e>\u001b[0m in \u001b[0;36mprocess_videos\u001b[0;34m(subfolder)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-b95cb820255e>\u001b[0m in \u001b[0;36mvideoCapture\u001b[0;34m(vid)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "responses = []\n",
        "\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/instagram-reels-dataset/reels\")\n",
        "\n",
        "subfolders = sorted(os.listdir())\n",
        "\n",
        "for subfolder in subfolders:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      result = process_videos(subfolder)\n",
        "\n",
        "      print(result)\n",
        "\n",
        "      responses.append(result)\n",
        "\n",
        "      if len(responses) > 320:\n",
        "        break\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/instagram-reels-dataset/reels\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXjbDPZ_u73j",
        "outputId": "de252803-b0eb-482c-c21a-bd9f53b1d3fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Correct: 131\n",
            "Total Incorrect: 1\n",
            "Mistakes: 182\n",
            "Accuracy: 0.42\n"
          ]
        }
      ],
      "source": [
        "def read_results(file_path):\n",
        "    results = []\n",
        "    with open(file_path, 'r', newline='', encoding='utf-8') as file:\n",
        "        reader = csv.reader(file)\n",
        "        results = [row[0] if row else \"\" for row in reader]  # Extract only the text from each row\n",
        "    return results\n",
        "\n",
        "def evaluate_results(results):\n",
        "    \"\"\"\n",
        "    Evaluate the results to categorize them into 'toxic' or 'not toxic' and calculate statistics.\n",
        "    \"\"\"\n",
        "    # Remove the header or any irrelevant first element\n",
        "    if results and not results[0].strip():\n",
        "        results.pop(0)\n",
        "\n",
        "    total = len(results)\n",
        "    correct = 0\n",
        "    incorrect = 0\n",
        "    mistake = 0\n",
        "\n",
        "    for text in results:\n",
        "        if not text.strip():\n",
        "            mistake += 1\n",
        "            continue\n",
        "\n",
        "        # Clean the string by replacing non-alphanumeric characters with a space\n",
        "        cleaned_str = re.sub(r'\\W+', ' ', text).lower()\n",
        "\n",
        "        # Split into words\n",
        "        words = cleaned_str.split()\n",
        "\n",
        "        if words:\n",
        "            last_word = words[-1]  # Last word in the cleaned list\n",
        "            second_last_word = words[-2] if len(words) > 1 else \"\"\n",
        "\n",
        "            # Check for correct \"not toxic\" evaluations\n",
        "            if last_word == 'nottoxic' or (second_last_word == 'not' and last_word == 'toxic'):\n",
        "                correct += 1\n",
        "            # Check for incorrect \"toxic\" evaluations\n",
        "            elif last_word == 'toxic' and second_last_word != 'not':\n",
        "                incorrect += 1\n",
        "            # Everything else is considered a mistake\n",
        "            else:\n",
        "                mistake += 1\n",
        "        else:\n",
        "            mistake += 1\n",
        "\n",
        "    if total > 330:\n",
        "        return 'Error: Total evaluations exceed the number of videos.'\n",
        "\n",
        "    accuracy = round(correct / total, 2) if total > 0 else 0\n",
        "\n",
        "    return f\"Total Correct: {correct}\\nTotal Incorrect: {incorrect}\\nMistakes: {mistake}\\nAccuracy: {accuracy}\"\n",
        "\n",
        "# Assuming the file is located in the given path\n",
        "file_path = '/content/drive/My Drive/instagram-reels-dataset/results/gpt-4-vision-preview-COT.csv'\n",
        "\n",
        "# Read and evaluate the results\n",
        "results = read_results(file_path)\n",
        "evaluation = evaluate_results(results)\n",
        "\n",
        "# Print the evaluation\n",
        "print(evaluation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jM-zbMXJqzPF"
      },
      "outputs": [],
      "source": [
        "#csv writer and append are weird for making files so this code is just to create the files and avoid the issue\n",
        "\n",
        "file_path = '/content/drive/My Drive/instagram-reels-dataset/results/'\n",
        "\n",
        "ogPath  = os.getcwd()\n",
        "\n",
        "os.chdir(file_path)\n",
        "\n",
        "with open('gpt-4-vision-preview-COT-full.csv', 'w', newline='', encoding='utf-8') as file: #full responsne\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow('')\n",
        "\n",
        "\n",
        "\n",
        "with open('gpt-4-vision-preview-COT.csv', 'w', newline='', encoding='utf-8') as file: #only toxic or not\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow('')\n",
        "\n",
        "os.chdir(ogPath)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BytK2obaabn3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}